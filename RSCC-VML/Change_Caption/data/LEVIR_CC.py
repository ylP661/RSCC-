import json
import os
from random import randint

import numpy as np
import torch
from imageio import imread
from torch.utils.data import Dataset

from preprocess_data import encode


class LEVIRCCDataset(Dataset):
    """LEVIR-CC dataset loader .

    Expected folder structure (typical):
        data_folder/
            train/A/*.png
            train/B/*.png
            val/A/*.png
            val/B/*.png
            test/A/*.png
            test/B/*.png
    """

    def __init__(self, data_folder, list_path, split, token_folder=None, vocab_file=None,
                 max_length=41, allow_unk=0, max_iters=None):
        self.mean = [0.39073 * 255, 0.38623 * 255, 0.32989 * 255]
        self.std = [0.15329 * 255, 0.14628 * 255, 0.13648 * 255]
        self.list_path = list_path
        self.split = split
        self.max_length = max_length

        assert self.split in {'train', 'val', 'test'}
        self.img_ids = [i_id.strip() for i_id in open(os.path.join(list_path + split + '.txt'))]

        self.word_vocab = None
        self.allow_unk = allow_unk
        if vocab_file is not None:
            with open(os.path.join(list_path + vocab_file + '.json'), 'r') as f:
                self.word_vocab = json.load(f)

        if max_iters is not None:
            n_repeat = int(np.ceil(max_iters / len(self.img_ids)))
            self.img_ids = self.img_ids * n_repeat + self.img_ids[:max_iters - n_repeat * len(self.img_ids)]

        self.files = []
        for name in self.img_ids:
            # Some list files may contain "xxx.png-3" to pick a specific caption id; we keep it compatible.
            if '-' in name:
                base_name = name.split('-')[0]
                token_id = name.split('-')[-1]
            else:
                base_name = name
                token_id = None

            img_fileA = os.path.join(data_folder + '/' + split + '/A/' + base_name)
            img_fileB = os.path.join(data_folder + '/' + split + '/B/' + base_name)

            imgA = imread(img_fileA)
            imgB = imread(img_fileB)

            if token_folder is not None:
                token_file = os.path.join(token_folder + base_name.split('.')[0] + '.txt')
            else:
                token_file = None

            self.files.append({
                "imgA": imgA,
                "imgB": imgB,
                "token": token_file,
                "token_id": token_id,
                "name": base_name
            })

    def __len__(self):
        return len(self.files)

    def __getitem__(self, index):
        datafiles = self.files[index]
        name = datafiles["name"]

        imgA = np.asarray(datafiles["imgA"], np.float32)
        imgB = np.asarray(datafiles["imgB"], np.float32)

        imgA = imgA.transpose(2, 0, 1)
        imgB = imgB.transpose(2, 0, 1)

        for i in range(len(self.mean)):
            imgA[i, :, :] = (imgA[i, :, :] - self.mean[i]) / self.std[i]
            imgB[i, :, :] = (imgB[i, :, :] - self.mean[i]) / self.std[i]

        # tokens
        if datafiles["token"] is not None and self.word_vocab is not None:
            caption = open(datafiles["token"], 'r', encoding='utf-8').read()
            caption_list = json.loads(caption)

            token_all = np.zeros((len(caption_list), self.max_length), dtype=int)
            token_all_len = np.zeros((len(caption_list), 1), dtype=int)

            for j, tokens in enumerate(caption_list):
                tokens_encode = encode(tokens, self.word_vocab, allow_unk=self.allow_unk == 1)
                token_all[j, :len(tokens_encode)] = tokens_encode
                token_all_len[j] = len(tokens_encode)

            if datafiles["token_id"] is not None:
                idx = int(datafiles["token_id"])
                token = token_all[idx]
                token_len = token_all_len[idx].item()
            else:
                j = randint(0, len(caption_list) - 1)
                token = token_all[j]
                token_len = token_all_len[j].item()
        else:
            token_all = np.zeros(1, dtype=int)
            token_all_len = np.zeros(1, dtype=int)
            token = np.zeros(1, dtype=int)
            token_len = np.zeros(1, dtype=int)

        # Keep return signature similar, but seg_label is removed (set to dummy zeros)
        dummy_seg = np.zeros((1,), dtype=int)
        return imgA.copy(), imgB.copy(), dummy_seg, token_all.copy(), token_all_len.copy(), token.copy(), np.array(token_len), name
